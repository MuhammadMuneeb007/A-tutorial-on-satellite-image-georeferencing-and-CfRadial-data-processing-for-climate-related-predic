{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f207de6",
   "metadata": {},
   "source": [
    "\n",
    "A simple code to scrape information from the google earth engine. Currently, the google earth engine does not allow to search for a dataset containing bands of a specific wavelength and for a particular duration.\n",
    "\n",
    "I considered only two parameters for the first version.\n",
    "\n",
    "Specify the date range.\n",
    "\n",
    "//Define the starting date.\n",
    "\n",
    "startingdate = date(2021, 1, 1)\n",
    "\n",
    "//Define the ending date.\n",
    "\n",
    "endingdate = date(2021, 12, 31)\n",
    "\n",
    "Specify the wavelength symbol.\n",
    "\n",
    "if 'µ' in soup.getText() or 'μ' in soup.getText():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242542ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from datetime import datetime\n",
    "from collections import namedtuple\n",
    "Range = namedtuple('Range', ['start', 'end'])\n",
    "from datetimerange import DateTimeRange\n",
    "from datetime import date\n",
    "MATCH_ALL = r'.*'\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)\n",
    "\n",
    "def like(string):\n",
    "    \"\"\"\n",
    "    Return a compiled regular expression that matches the given\n",
    "    string with any prefix and postfix, e.g. if string = \"hello\",\n",
    "    the returned regex matches r\".*hello.*\"\n",
    "    \"\"\"\n",
    "    string_ = string\n",
    "    if not isinstance(string_, str):\n",
    "        string_ = str(string_)\n",
    "    regex = MATCH_ALL + re.escape(string_) + MATCH_ALL\n",
    "    return re.compile(regex, flags=re.DOTALL)\n",
    "\n",
    "def find_by_text(soup, text, tag, **kwargs):\n",
    " \n",
    "    elements = soup.find_all(tag, **kwargs)\n",
    "    matches = []\n",
    "    for element in elements:\n",
    "        if element.find(text=like(text)):\n",
    "            matches.append(element)\n",
    "    if len(matches) > 1:\n",
    "        raise ValueError(\"Too many matches:\\n\" + \"\\n\".join(matches))\n",
    "    elif len(matches) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return matches[0] \n",
    "\n",
    "\n",
    "def with_in_date_range(soup,startingdate,endingdate):\n",
    "    dates = find_by_text(soup,'Dataset Availability','dl').findAll('dd')[0].text.split('–')\n",
    "    starts = datetime.fromisoformat(dates[0][0:10]).astimezone(timezone.utc).strftime('%Y-%m-%d').split(\" \")[0].split(\"-\")\n",
    "    ends = datetime.fromisoformat(dates[1][0:10]).astimezone(timezone.utc).strftime('%Y-%m-%d').split(\" \")[0].split(\"-\")\n",
    "    if date(int(starts[0]),int(starts[1]),int(starts[2]))<= startingdate and date(int(ends[0]),int(ends[1]),int(ends[2]))>= endingdate:\n",
    "        return 1\n",
    "    else:\n",
    "        #print(\"Dataset is not available in the specified range.\")\n",
    "        return 0\n",
    "\n",
    "def get_Text(url):\n",
    "    reqs = requests.get(url)\n",
    "    soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "# URL contains the catalog for all the datasets on the google earth engine.\n",
    "\n",
    "url=\"https://developers.google.com/earth-engine/datasets/catalog\"\n",
    "# Define the starting date.\n",
    "startingdate = date(2021, 1, 1)\n",
    "# Define the ending date.\n",
    "endingdate = date(2021, 12, 31)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "urls = []\n",
    "# Find the link to each dataset.\n",
    "data = get_Text(url)\n",
    "data = data.findAll('td',attrs={'class':'ee-dataset'})\n",
    "count = 0\n",
    "\n",
    "# Store the links.\n",
    "finallinks = []\n",
    "for div in data:\n",
    " datasets = div.findAll('a')\n",
    " for dataset in datasets:\n",
    "  soup = get_Text(\"https://developers.google.com\" + dataset['href'])\n",
    "  \n",
    "  # Check if the dataset on google earth engine is within the specified date range.\n",
    "\n",
    "  if with_in_date_range(soup,startingdate,endingdate):\n",
    "   # If the dataset is within range, search for the specific keywords in the documents.\n",
    "   [s.extract() for s in soup(['style', 'script', '[document]', 'head', 'title'])]\n",
    "   if 'µ' in soup.getText() or 'μ' in soup.getText():\n",
    "    #if \"cloud\" in soup.getText() or \"infrared\" in soup.getText() or 'µ' in soup.getText():\n",
    "    print(\"Link :\",count, \"https://developers.google.com\" + dataset['href'])\n",
    "\n",
    "    # Append the link to final links.\n",
    "    finallinks.append(\"https://developers.google.com\" + dataset['href'])\n",
    "\n",
    "    count=count+1\n",
    "\n",
    "\n",
    "print(\"Number of datasets: \",count)\n",
    "\n",
    "# Save the links in file.\n",
    "with open('finallinks.txt', 'w') as f:\n",
    "    for line in finallinks:\n",
    "        f.write(line)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50320c3",
   "metadata": {},
   "source": [
    "Code to download images from google earth engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0408b8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Latitude  Longitude Location\n",
      "0   24.3722     54.467   Center\n",
      "['tcdc_2021010100', 'tcdc_2021010106', 'tcdc_2021010112', 'tcdc_2021010118', 'tcdc_2021010200', 'tcdc_2021010206', 'tcdc_2021010212', 'tcdc_2021010218', 'tcdc_2021010300', 'tcdc_2021010306', 'tcdc_2021010312', 'tcdc_2021010318', 'tcdc_2021010400', 'tcdc_2021010406', 'tcdc_2021010412', 'tcdc_2021010418', 'tcdc_2021010500', 'tcdc_2021010506', 'tcdc_2021010512', 'tcdc_2021010518', 'tcdc_2021010600', 'tcdc_2021010606', 'tcdc_2021010612', 'tcdc_2021010618', 'tcdc_2021010700', 'tcdc_2021010706', 'tcdc_2021010712', 'tcdc_2021010718', 'tcdc_2021010800', 'tcdc_2021010806', 'tcdc_2021010812', 'tcdc_2021010818', 'tcdc_2021010900', 'tcdc_2021010906', 'tcdc_2021010912', 'tcdc_2021010918']\n",
      "Total number of images: 36\n",
      "\n",
      "Exporting 1/36: tcdc_2021010100.tif\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/e39891753eef767455c395427b689171-99aff58937f0282765e46e3841199749:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /home/muneeb/Desktop/Paper2/Procedure 5/Center/images/tcdc_2021010100.tif\n",
      "\n",
      "\n",
      "Exporting 2/36: tcdc_2021010106.tif\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/21a18d356e96da508adf7b945eae8962-717d3b948172d89d2507c399d29911f4:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /home/muneeb/Desktop/Paper2/Procedure 5/Center/images/tcdc_2021010106.tif\n",
      "\n",
      "\n",
      "Exporting 3/36: tcdc_2021010112.tif\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/f3db2fd755dc8710acc565a8cf42f2c3-9962a0794d2665e7ebf94e1a78039f00:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /home/muneeb/Desktop/Paper2/Procedure 5/Center/images/tcdc_2021010112.tif\n",
      "\n",
      "\n",
      "Exporting 4/36: tcdc_2021010118.tif\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/63cae75b07c29c4e80db57efb2aa501d-f8934014aa37e4bab10dbc88b49244b0:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /home/muneeb/Desktop/Paper2/Procedure 5/Center/images/tcdc_2021010118.tif\n",
      "\n",
      "\n",
      "Exporting 5/36: tcdc_2021010200.tif\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/d59c11d12a9316c882827ae697e00f24-da228af86f84903411c9c113d1aea86f:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /home/muneeb/Desktop/Paper2/Procedure 5/Center/images/tcdc_2021010200.tif\n",
      "\n",
      "\n",
      "Exporting 6/36: tcdc_2021010206.tif\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/115f36b91fbc877b85abf50dc33133be-d8838bd0ae62c3324f60441e619755f3:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /home/muneeb/Desktop/Paper2/Procedure 5/Center/images/tcdc_2021010206.tif\n",
      "\n",
      "\n",
      "Exporting 7/36: tcdc_2021010212.tif\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/322927326df2f04fed46828ba77cda69-5b6a656904b0c6b4bd1ca7db48fbdd25:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /home/muneeb/Desktop/Paper2/Procedure 5/Center/images/tcdc_2021010212.tif\n",
      "\n",
      "\n",
      "Exporting 8/36: tcdc_2021010218.tif\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/e9b96fec5639e99252ecb9fa441144f5-cc4d6ad99eb97b13787d9a5ba321ef71:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /home/muneeb/Desktop/Paper2/Procedure 5/Center/images/tcdc_2021010218.tif\n",
      "\n",
      "\n",
      "Exporting 9/36: tcdc_2021010300.tif\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/86144de6fc33d00f2669513962d4df21-3529f4d96be21b35a55b52ff30ecd249:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /home/muneeb/Desktop/Paper2/Procedure 5/Center/images/tcdc_2021010300.tif\n",
      "\n",
      "\n",
      "Exporting 10/36: tcdc_2021010306.tif\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/f0306d68b0524703c2613e5438d4b072-0dbcc3b7f4e68f388dd53fca2182c19a:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /home/muneeb/Desktop/Paper2/Procedure 5/Center/images/tcdc_2021010306.tif\n",
      "\n",
      "\n",
      "Exporting 11/36: tcdc_2021010312.tif\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/257103f65525ab93cb3d7484fad591c5-42b904bb4d1dd0db58543a46c071e19a:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /home/muneeb/Desktop/Paper2/Procedure 5/Center/images/tcdc_2021010312.tif\n",
      "\n",
      "\n",
      "Exporting 12/36: tcdc_2021010318.tif\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/bfc15c3ace0c4e4e55257d33832d6a56-5fb4ae86a494eb1cd9ac601cad96a8b6:getPixels\n",
      "Please wait ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from heapq import merge\n",
    "from operator import index\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.neighbors\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from multiprocessing import Process\n",
    "import ee\n",
    "import pandas as pd\n",
    "import ee\n",
    "import ee\n",
    "import geemap\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio.plot import show_hist\n",
    "from rasterio.plot import show_hist\n",
    "\n",
    "\n",
    "ee.Initialize()\n",
    "\n",
    "# Helper function to convert the square into earth engine polygon.\n",
    "\n",
    "def findpolygon_earthengine(row):\n",
    " return [[row['topleft_long'],row['topleft_lat']],\n",
    " [row['topright_long'],row['topright_lat']],\n",
    " [row['bottomright_long'],row['bottomright_lat']],\n",
    " [row['bottomleft_long'],row['bottomleft_lat']], \n",
    " [row['topleft_long'],row['topleft_lat']]]\n",
    "\n",
    "# Helper function to convert the square into geopandas polygon.\n",
    "def findpolygon_geopandas(row):\n",
    "  return Polygon([( row['topleft_long'],row['topleft_lat'])\n",
    "    , ( row['topright_long'],row['topright_lat'])\n",
    "    ,(row['bottomright_long'],row['bottomright_lat'] )\n",
    "    , ( row['bottomleft_long'],row['bottomleft_lat'])\n",
    "    , (row['topleft_long'],row['topleft_lat'] )])\n",
    "\n",
    "def makeboxes(data):\n",
    "  # This constant value is added to each longitude and latitude value to make a polygon.\n",
    "  constant = 0.1\n",
    "  data['topleft_lat'] = data['Latitude'] - constant\n",
    "  data['topleft_long'] = data['Longitude'] -constant\n",
    "  data['topright_lat'] = data['Latitude'] - constant\n",
    "  data['topright_long'] = data['Longitude'] + constant\n",
    "  data['bottomleft_lat'] = data['Latitude'] + constant\n",
    "  data['bottomleft_long'] = data['Longitude'] - constant\n",
    "  data['bottomright_lat'] = data['Latitude'] +constant\n",
    "  data['bottomright_long'] = data['Longitude'] + constant\n",
    "  data['p'] = data.apply(findpolygon_geopandas, axis=1)\n",
    "  data['coords'] = data.apply(findpolygon_earthengine, axis=1)\n",
    "  return data\n",
    "\n",
    "\n",
    "def sorted_nicely( l ):\n",
    "    convert = lambda text: int(text) if text.isdigit() else text\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "    return sorted(l, key = alphanum_key)\n",
    "\n",
    "location = pd.DataFrame()\n",
    "location['Latitude'] = [24.3722]\n",
    "location['Longitude'] = [54.467]\n",
    "location['Location'] = [\"Center\"]\n",
    "print(location)\n",
    "\n",
    "location = makeboxes(location)\n",
    "\n",
    "# Here, we defined a specific dataset containing cloud presence information.\n",
    "# Define the google earth engine dataset and the corresponding band.\n",
    "names = ['NOAA/NCEP_DOE_RE2/total_cloud_coverage']\n",
    "bands = ['tcdc']\n",
    "datasetnames = pd.DataFrame()\n",
    "datasetnames['name'] = names\n",
    "datasetnames['bands'] = bands\n",
    "\n",
    "# Define the starting and the ending range.\n",
    "i_date = '2021-01-01'\n",
    "f_date =  '2021-01-02'\n",
    "\n",
    "# Use this function to download earth engine images for each station separately.\n",
    "def downloadindividualdataset():\n",
    " for index, row in location.iterrows():\n",
    "  roi = ee.Geometry.Polygon(row['coords'])\n",
    "  for index2,row2 in datasetnames.iterrows():\n",
    "   # Read the earth engine dataset.\n",
    "   collection = (ee.ImageCollection(row2['name']).select(row2['bands']).filterDate(i_date ,f_date).filterBounds(roi))\n",
    "   \n",
    "   # Crop the specific portion of an image.\n",
    "   collection =  collection.map(lambda image: image.clip(roi))\n",
    "   \n",
    "   # Make a directory with a station name to store the images.  \n",
    "   if not os.path.isdir(row['Location']): \n",
    "    os.mkdir(row['Location'])   \n",
    "   directoryname = row['Location']+os.sep+\"images\" \n",
    "   if not os.path.isdir(directoryname): \n",
    "    os.mkdir(directoryname)\n",
    "   print(collection.aggregate_array('system:index').getInfo())\n",
    "   geemap.ee_export_image_collection(collection, out_dir=directoryname)\n",
    "   geemap.ee_export_image_collection_to_drive(collection, folder='export', scale=30)\n",
    "\n",
    "downloadindividualdataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294ec0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2f8096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
